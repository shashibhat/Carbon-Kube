Carbon-Kube: Full Design Document for Implementation

Purpose: This document provides a complete, actionable blueprint for implementing Carbon-Kube using AI-assisted code generation (e.g., via Grok or similar tools). Each section includes precise specifications, pseudocode, interfaces, and prompts for generating code snippets. Use this to iteratively generate components—e.g., "Generate Go code for the mutator based on Section 4.1."

1. Executive Summary
1.1 Project Overview
Carbon-Kube is an open-source Kubernetes scheduler plugin that enables carbon-aware workload scheduling for big data pipelines (e.g., Spark and Flink jobs). It reduces CO₂ emissions by 5-15% through preemptive migration of non-urgent jobs to low-emission AWS zones or times, while maintaining 98% uptime and zero SLA violations.
Core Innovation:

Extends Katalyst (leveraging 25% resource efficiency gains from your contributions).
Integrates real-time carbon forecasts via Electricity Maps and NOAA APIs.
Deploys via one-click AWS CDK with Helm, including EKS lab for testing.

Tech Stack:

Languages: Go (scheduler mutator), Python (CDK, RL tuner, poller scripts).
Frameworks: Kubernetes 1.28+, Katalyst v0.7+, AWS CDK v2, Helm v3.
APIs: Electricity Maps (REST), NOAA (JSON), AWS Carbon Footprint (SDK).
Monitoring: Prometheus, Grafana.
License: Apache 2.0.

EB1 Relevance: Demonstrates original impact in green AI—reproducible evals show 80kg CO₂ savings per 1PB job; cite repo commits as authorship proof.
1.2 Implementation Roadmap

Week 1: Generate core components (mutator, poller) using this doc.
Week 2: Build deployment (CDK, Helm) and monitoring.
Week 3: Implement RL tuner and tests.
Week 4: Evals, docs, release v1.0.

AI Generation Prompts: For each section, use: "Write [language] code for [component] following these specs: [paste subsection]. Ensure [constraints, e.g., error handling]."

2. Requirements
2.1 Functional Requirements

FR1: Poll carbon intensity every 5 minutes and cache forecasts.
FR2: Extend Katalyst scoring with emission_score; rank nodes by ascending emissions.
FR3: Migrate jobs if score > threshold (e.g., 200g CO₂/kWh) and latency risk <5%.
FR4: Tune thresholds via lightweight RL (offline replay on historical migrations).
FR5: Export metrics (e.g., carbon_saved_kg) to Prometheus.
FR6: One-click EKS deploy with test workloads (100GB-1PB Flink jobs).
FR7: Generate savings graphs via Jupyter.

2.2 Non-Functional Requirements

Performance: Scheduler overhead <1ms/pod; migrations <30s.
Scalability: Supports 1000 nodes, 10k jobs/day.
Reliability: 99.9% API success; 24h cache fallback.
Security: Secrets via K8s; no PII in logs.
Observability: Grafana dashboards for all KPIs.
Testability: 80% coverage; EKS lab with baselines/optimized runs.

2.3 Data Models

ZonalIntensity: {zone: string, intensity: float (gCO₂/kWh), timestamp: int64, forecast: [24h array]}.
EmissionScore: {nodeName: string, score: float, reqCPU: int64, reqMem: int64}.
MigrationEvent: {jobID: string, fromZone: string, toZone: string, savedCO2: float, latencyDelta: float}.
RLState: {intensityDelta: float, latencyRisk: float, action: int (0=hold, 1=migrate)}; Reward = savedCO2 - (latencyDelta * penaltyFactor).


3. System Architecture
3.1 High-Level Diagram
(Generate via AI: "Create draw.io XML for this flow: [describe below]. Export as architecture.png.")
text[External APIs: Electricity Maps/NOAA] 
    ↓ (HTTPS, 5m CronJob)
[ConfigMap: Zonal Scores (JSON Cache)] 
    ↓ (Katalyst Hook)
[Go Mutator: Compute emission_score] → [Node Ranking (Lowest Emissions First)]
    ↓ (If Threshold Hit)
[Karpenter: Taint/Evict → Reschedule Pod] 
    ↓ (Post-Migration)
[Python RL Sidecar: Replay & Tune Threshold] → [Update ConfigMap]
    ↓ (All Phases)
[Prometheus Scrape] → [Grafana Dashboards: Savings Graphs]
3.2 Component Interactions

Deployment: CDK → EKS Cluster + NodeGroups (us-west-2 green, us-east-1 dirty).
Runtime: Katalyst loads mutator.so → Polls trigger scoring → Karpenter handles migration.
Feedback: Sidecar watches events via Kubernetes API → RL updates thresholds.

3.3 Interfaces

Katalyst Plugin Interface (Go):
gotype Plugin interface {
    Name() string
    Execute(ctx context.Context, pod *v1.Pod, nodes []*v1.Node) (map[string]float64, bool) // Returns scores, done
}

Poller Output: Kubernetes ConfigMap {data: {zones: JSON(ZonalIntensity[])}}.
RL API: gRPC (optional) or in-memory: Tune(rlState []RLState) -> newThreshold: float.


4. Detailed Component Design
4.1 Scheduler Mutator (Go)
Purpose: Hooks into Katalyst's scoring phase to add emission-based ranking.
Specs:

Location: /pkg/emissionplugin/plugin.go.
Dependencies: k8s.io/api/core/v1, kubewharf/katalyst/pkg/scheduler, net/http for cache read.
Error Handling: Log warnings; fallback to zero-score if ConfigMap missing.
Build: go build -buildmode=plugin -o mutator.so.

Pseudocode:
textfunc (p *EmissionPlugin) Execute(ctx, pod, nodes):
    scores = {}
    configMap = kubeClient.GetConfigMap("carbon-scores")  // JSON parse to ZonalIntensity map
    for node in nodes:
        zone = extractZone(node.Labels["topology.kubernetes.io/zone"])  // e.g., "us-west-2a"
        intensity = configMap[zone].intensity  // gCO2/kWh
        req = getPodRequests(pod)  // CPU in millicores
        scores[node.Name] = float64(intensity) * (req.CPU / 1000.0)  // Normalize to kWh equiv
    sortScoresAscending(scores)  // Heap or sort.Slice
    return scores, true
AI Prompt: "Implement the full Go EmissionPlugin struct and Execute method per this pseudocode. Include imports, zone extraction from labels, and Prometheus metric export for scores. Add unit tests with mock nodes."
4.2 API Poller (Python/Bash Hybrid)
Purpose: Fetches and caches zonal data every 5m.
Specs:

Location: /charts/templates/poller-cronjob.yaml (manifest); /scripts/poller.py (script).
Dependencies: requests (Python), jq (Bash fallback).
Frequency: Cron * */5 * * * *.
Cache: Write JSON to ConfigMap via kubectl patch.
Fallback: If API fails, use 24h NOAA forecast or avg (200g).

Pseudocode (Python):
textimport requests, json, os
from kubernetes import client, config

def poll():
    api_key = os.getenv('ELECTRICITY_MAPS_API_KEY')
    zones = ['US-WA-SEAT', 'US-VA-NOR']  # Map to AWS
    intensities = {}
    for zone in zones:
        resp = requests.get(f"https://api.electricitymaps.com/v3/carbon-intensity?zone={zone}", headers={'auth-token': api_key})
        if resp.ok:
            data = resp.json()
            intensities[zone] = {'intensity': data['carbonIntensity'], 'forecast': data.get('forecast', [])}
        else:
            # Fallback NOAA solar/wind proxy
            noaa_resp = requests.get("https://api.weather.gov/zones?point=47.6,-122.3")  # Seattle example
            intensities[zone] = {'intensity': 150.0, 'forecast': []}  # Default green
    # Patch ConfigMap
    config.load_kube_config()
    v1 = client.CoreV1Api()
    v1.patch_namespaced_config_map(name="carbon-scores", namespace="default", body={'data': {'zones': json.dumps(intensities)}})
AI Prompt: "Write the full poller.py script with error handling, logging (via logging module), and NOAA fallback. Generate the CronJob YAML that mounts the script as a volume and runs it with env vars."
4.3 RL Tuner (Python)
Purpose: Offline replay to adapt thresholds (e.g., start at 200g, tune ±10% based on rewards).
Specs:

Location: /charts/templates/rl-sidecar.yaml (Deployment sidecar).
Dependencies: stable-baselines3, gym (for env), kubernetes client.
Replay Buffer: In-memory list of 1000 MigrationEvents.
Training: 10 episodes/day; Reward = savedCO2 - (latencyDelta * 10).
Update: Patch ConfigMap threshold.

Pseudocode:
textimport gym, stable_baselines3 as sb3
from collections import deque

class CarbonEnv(gym.Env):
    def step(action):  # 0: hold, 1: migrate
        if action == 1:
            saved = simulate_migration(state.intensityDelta)
            penalty = state.latencyRisk * 10
            reward = saved - penalty
        return next_state, reward, done, {}

replay_buffer = deque(maxlen=1000)
model = sb3.PPO("MlpPolicy", env=CarbonEnv(), verbose=0)

def tune():
    for event in replay_buffer:  # From K8s events
        state = RLState(event.intensityDelta, event.latencyRisk)
        action, _ = model.predict(state)
        reward = compute_reward(event)
        model.learn(total_timesteps=1)  # Offline step
    new_thresh = model.get_threshold()  # Custom method
    patch_configmap(new_thresh)
AI Prompt: "Implement the CarbonEnv Gym env and PPO tuner class. Add buffer population from K8s API (watch MigrationEvents CRD). Include a main loop that runs every hour."
4.4 Deployment: AWS CDK (Python)
Purpose: Provisions EKS + installs everything.
Specs:

Location: /cdk/app.py.
Dependencies: aws-cdk-lib, constructs.
Stack: EKS Cluster (2 nodegroups), IAM roles (API access), S3 for logs.
Post-Deploy: Install Helm chart, seed test jobs.

Skeleton Code:
pythonfrom aws_cdk import Stack, App
from aws_eks import Cluster
from constructs import Construct

class CarbonKubeStack(Stack):
    def __init__(self, scope: Construct, id: str):
        super().__init__(scope, id)
        cluster = Cluster(self, "EKSCluster",
            version="1.28",
            default_capacity=0,
            # Add nodegroups: green/us-west-2 t3.medium x2, dirty/us-east-1 x2
        )
        # IAM: Policy for Carbon Footprint API
        # S3 Bucket for metrics
        # CustomResource: helm install carbon-kube
        # Lambda: Auto-teardown after 24h
AI Prompt: "Complete the CDK Stack with EKS nodegroups, IAM for Electricity Maps proxy (if needed), and a CustomResource to run helm install. Add outputs for kubeconfig and Grafana URL."
4.5 Helm Chart
Purpose: Packages mutator, poller, RL, monitoring.
Specs:

Location: /charts/carbon-kube/.
Templates: Deployment (mutator), CronJob (poller), Sidecar (RL), ConfigMap (thresholds), PrometheusRule.
Values: As in README (threshold: 200, zones: [...], apiKey: secret).

AI Prompt: "Generate full Helm templates: mutator Deployment with plugin mount, poller CronJob, and values.yaml. Include secrets for API key."
4.6 Monitoring & Viz
Specs:

Prometheus Metrics: carbon_intensity{zone}, migrations_total, saved_co2_kg.
Grafana: Dashboard JSON with panels (bars for savings, lines for intensity).
Jupyter: /test/plot_savings.ipynb – Load S3 CSV, plot with matplotlib.

AI Prompt: "Write Prometheus exporter code in Go (for mutator). Generate Grafana dashboard JSON for CO₂ savings. Create Jupyter notebook to plot baseline vs. optimized from CSV."

5. Testing & Evaluation
5.1 Unit/Integration Tests

Go: go test ./pkg/... – Mock nodes, assert scores.
Python: pytest scripts/ – Mock requests, assert ConfigMap patches.
Helm: helm lint, helm template | kubeval.

5.2 EKS Lab Tests

Baselines: Static schedule, midday runs → Measure CO₂ via AWS SDK.
Optimized: Enable plugin → Assert migrations, 16% savings.
Scale: kubectl scale to 100 jobs; Locust load test.

AI Prompt: "Generate Go unit tests for mutator (3 cases: green/low, dirty/high, fallback). Write pytest for poller with mocked API responses."
5.3 KPIs & Graphs

























KPITargetMeasurementCO₂ Savings5-15%AWS API kg/runLatency Delta<5%Job completion timeOverhead<1%Scheduler latency
AI Prompt: "Script to run 10 baseline/10 optimized tests in EKS; export CSV for Jupyter."

6. Deployment & Ops

CI/CD: GitHub Actions – make build-test-deploy.
Makefile Targets: make build (Go), make helm-package, make test-eks.
Rollout: Blue-green via Argo; Monitor via Grafana alerts (e.g., migrations >10/h).


7. Risks & Mitigations

Risk: API Rate Limits – Mitigate: Cache 1h, exponential backoff.
Risk: RL Over-Tuning – Mitigate: Constrain actions ±20%.
Risk: Zone Parity – Mitigate: Fallback to same-zone delay.


8. Future Enhancements

Multi-Cloud: Terraform for GCP.
Advanced: Online RL with Ray.
Upstream: PR to Katalyst.