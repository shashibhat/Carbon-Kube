{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carbon-Kube Evaluation Framework - Getting Started\n",
    "\n",
    "This notebook provides a comprehensive introduction to the Carbon-Kube evaluation framework for scientific evaluation of carbon-efficient Kubernetes scheduling algorithms.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The evaluation framework provides:\n",
    "- **Baseline Management**: Compare against established baselines\n",
    "- **Statistical Analysis**: Rigorous statistical testing and analysis\n",
    "- **Ablation Studies**: Understand feature importance\n",
    "- **Reproducibility**: Ensure experiments can be reproduced\n",
    "- **Artifact Management**: Store and version experimental artifacts\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Make sure you have:\n",
    "1. Run the setup script: `./evaluation/setup.sh`\n",
    "2. Activated the Python environment: `source venv/bin/activate`\n",
    "3. Set environment variables: `export $(cat evaluation/.env | xargs)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Datasets\n",
    "\n",
    "Let's start by loading the available datasets and exploring their structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset configuration\n",
    "data_path = Path('../data')\n",
    "config_path = data_path / 'dataset_config.yaml'\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    dataset_config = yaml.safe_load(f)\n",
    "\n",
    "print(\"üìä Available Dataset Categories:\")\n",
    "for category in dataset_config['datasets'].keys():\n",
    "    datasets = dataset_config['datasets'][category]\n",
    "    print(f\"  {category}: {len(datasets)} datasets\")\n",
    "    for name in list(datasets.keys())[:3]:  # Show first 3\n",
    "        print(f\"    - {name}\")\n",
    "    if len(datasets) > 3:\n",
    "        print(f\"    ... and {len(datasets) - 3} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the main synthetic dataset\n",
    "main_dataset_path = data_path / 'synthetic' / 'carbon_efficiency_main.csv'\n",
    "df_main = pd.read_csv(main_dataset_path)\n",
    "\n",
    "print(f\"üìà Main Dataset Shape: {df_main.shape}\")\n",
    "print(f\"üìÖ Date Range: {df_main['timestamp'].min()} to {df_main['timestamp'].max()}\")\n",
    "print(\"\\nüîç Dataset Info:\")\n",
    "df_main.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data\n",
    "print(\"üìã Sample Data (first 5 rows):\")\n",
    "display(df_main.head())\n",
    "\n",
    "print(\"\\nüìä Statistical Summary:\")\n",
    "display(df_main.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration and Visualization\n",
    "\n",
    "Let's explore the key metrics and their relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scheduler distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Scheduler distribution\n",
    "scheduler_counts = df_main['scheduler'].value_counts()\n",
    "axes[0, 0].pie(scheduler_counts.values, labels=scheduler_counts.index, autopct='%1.1f%%')\n",
    "axes[0, 0].set_title('Scheduler Distribution')\n",
    "\n",
    "# Node type distribution\n",
    "node_counts = df_main['node_type'].value_counts()\n",
    "axes[0, 1].bar(node_counts.index, node_counts.values)\n",
    "axes[0, 1].set_title('Node Type Distribution')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Workload type distribution\n",
    "workload_counts = df_main['workload_type'].value_counts()\n",
    "axes[1, 0].bar(workload_counts.index, workload_counts.values, color='orange')\n",
    "axes[1, 0].set_title('Workload Type Distribution')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Carbon efficiency distribution\n",
    "axes[1, 1].hist(df_main['carbon_efficiency'], bins=30, alpha=0.7, color='green')\n",
    "axes[1, 1].set_title('Carbon Efficiency Distribution')\n",
    "axes[1, 1].set_xlabel('Carbon Efficiency')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key metrics comparison by scheduler\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "metrics = ['carbon_efficiency', 'energy_consumption', 'performance_score', 'resource_utilization']\n",
    "titles = ['Carbon Efficiency', 'Energy Consumption (W)', 'Performance Score', 'Resource Utilization (%)']\n",
    "\n",
    "for i, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "    row, col = i // 2, i % 2\n",
    "    \n",
    "    # Box plot by scheduler\n",
    "    df_main.boxplot(column=metric, by='scheduler', ax=axes[row, col])\n",
    "    axes[row, col].set_title(f'{title} by Scheduler')\n",
    "    axes[row, col].set_xlabel('Scheduler')\n",
    "    axes[row, col].set_ylabel(title)\n",
    "    \n",
    "plt.suptitle('')  # Remove automatic title\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Statistical Analysis\n",
    "\n",
    "Let's perform some basic statistical analysis to understand scheduler performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics by scheduler\n",
    "scheduler_stats = df_main.groupby('scheduler')[['carbon_efficiency', 'energy_consumption', 'performance_score']].agg([\n",
    "    'mean', 'std', 'min', 'max', 'count'\n",
    "]).round(3)\n",
    "\n",
    "print(\"üìä Scheduler Performance Summary:\")\n",
    "display(scheduler_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "numeric_cols = ['carbon_efficiency', 'energy_consumption', 'performance_score', \n",
    "                'cpu_utilization', 'memory_utilization', 'response_time', 'throughput']\n",
    "\n",
    "correlation_matrix = df_main[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Key Metrics')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline Comparison\n",
    "\n",
    "Let's compare different schedulers against the default Kubernetes scheduler as a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline datasets\n",
    "baseline_datasets = {}\n",
    "baseline_names = ['kubernetes_default', 'carbon_aware_v1', 'energy_efficient', 'performance_optimized']\n",
    "\n",
    "for name in baseline_names:\n",
    "    try:\n",
    "        path = data_path / 'synthetic' / f'baseline_{name}.csv'\n",
    "        baseline_datasets[name] = pd.read_csv(path)\n",
    "        print(f\"‚úÖ Loaded {name}: {len(baseline_datasets[name])} samples\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Could not load {name}\")\n",
    "\n",
    "print(f\"\\nüìä Loaded {len(baseline_datasets)} baseline datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baselines\n",
    "if baseline_datasets:\n",
    "    baseline_comparison = pd.DataFrame()\n",
    "    \n",
    "    for name, df in baseline_datasets.items():\n",
    "        stats = df[['carbon_efficiency', 'energy_consumption', 'performance_score']].mean()\n",
    "        stats.name = name\n",
    "        baseline_comparison = pd.concat([baseline_comparison, stats], axis=1)\n",
    "    \n",
    "    baseline_comparison = baseline_comparison.T\n",
    "    \n",
    "    print(\"üèÜ Baseline Comparison (Mean Values):\")\n",
    "    display(baseline_comparison.round(3))\n",
    "    \n",
    "    # Visualize baseline comparison\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    metrics = ['carbon_efficiency', 'energy_consumption', 'performance_score']\n",
    "    titles = ['Carbon Efficiency', 'Energy Consumption', 'Performance Score']\n",
    "    \n",
    "    for i, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "        baseline_comparison[metric].plot(kind='bar', ax=axes[i], color='skyblue')\n",
    "        axes[i].set_title(f'{title} Comparison')\n",
    "        axes[i].set_ylabel(title)\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical Significance Testing\n",
    "\n",
    "Let's perform statistical tests to determine if differences between schedulers are significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def perform_statistical_tests(df, metric, group_col='scheduler'):\n",
    "    \"\"\"Perform statistical tests between groups\"\"\"\n",
    "    groups = df[group_col].unique()\n",
    "    results = []\n",
    "    \n",
    "    for i, group1 in enumerate(groups):\n",
    "        for group2 in groups[i+1:]:\n",
    "            data1 = df[df[group_col] == group1][metric]\n",
    "            data2 = df[df[group_col] == group2][metric]\n",
    "            \n",
    "            # T-test\n",
    "            t_stat, t_pval = stats.ttest_ind(data1, data2)\n",
    "            \n",
    "            # Mann-Whitney U test (non-parametric)\n",
    "            u_stat, u_pval = stats.mannwhitneyu(data1, data2, alternative='two-sided')\n",
    "            \n",
    "            # Effect size (Cohen's d)\n",
    "            pooled_std = np.sqrt(((len(data1) - 1) * data1.var() + (len(data2) - 1) * data2.var()) / \n",
    "                                (len(data1) + len(data2) - 2))\n",
    "            cohens_d = (data1.mean() - data2.mean()) / pooled_std\n",
    "            \n",
    "            results.append({\n",
    "                'Group 1': group1,\n",
    "                'Group 2': group2,\n",
    "                'Mean 1': data1.mean(),\n",
    "                'Mean 2': data2.mean(),\n",
    "                'T-test p-value': t_pval,\n",
    "                'Mann-Whitney p-value': u_pval,\n",
    "                'Effect Size (Cohen\\'s d)': cohens_d,\n",
    "                'Significant (p<0.05)': t_pval < 0.05\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Test carbon efficiency differences\n",
    "carbon_tests = perform_statistical_tests(df_main, 'carbon_efficiency')\n",
    "print(\"üß™ Statistical Tests for Carbon Efficiency:\")\n",
    "display(carbon_tests.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test energy consumption differences\n",
    "energy_tests = perform_statistical_tests(df_main, 'energy_consumption')\n",
    "print(\"üß™ Statistical Tests for Energy Consumption:\")\n",
    "display(energy_tests.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Time Series Analysis\n",
    "\n",
    "Let's analyze temporal patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load time series dataset\n",
    "timeseries_path = data_path / 'synthetic' / 'timeseries_14days.csv'\n",
    "df_ts = pd.read_csv(timeseries_path)\n",
    "df_ts['timestamp'] = pd.to_datetime(df_ts['timestamp'])\n",
    "df_ts = df_ts.sort_values('timestamp')\n",
    "\n",
    "print(f\"üìà Time Series Dataset: {len(df_ts)} samples\")\n",
    "print(f\"üìÖ Date Range: {df_ts['timestamp'].min()} to {df_ts['timestamp'].max()}\")\n",
    "\n",
    "# Plot time series\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "# Carbon efficiency over time\n",
    "axes[0].plot(df_ts['timestamp'], df_ts['carbon_efficiency'], alpha=0.7, color='green')\n",
    "axes[0].set_title('Carbon Efficiency Over Time')\n",
    "axes[0].set_ylabel('Carbon Efficiency')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Energy consumption over time\n",
    "axes[1].plot(df_ts['timestamp'], df_ts['energy_consumption'], alpha=0.7, color='red')\n",
    "axes[1].set_title('Energy Consumption Over Time')\n",
    "axes[1].set_ylabel('Energy Consumption (W)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Load factor over time\n",
    "axes[2].plot(df_ts['timestamp'], df_ts['load_factor'], alpha=0.7, color='blue')\n",
    "axes[2].set_title('System Load Factor Over Time')\n",
    "axes[2].set_ylabel('Load Factor')\n",
    "axes[2].set_xlabel('Time')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Recommendations\n",
    "\n",
    "Based on our analysis, let's generate some recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(df):\n",
    "    \"\"\"Generate performance recommendations based on data analysis\"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    # Analyze scheduler performance\n",
    "    scheduler_perf = df.groupby('scheduler')[['carbon_efficiency', 'energy_consumption', 'performance_score']].mean()\n",
    "    \n",
    "    # Best carbon efficiency\n",
    "    best_carbon = scheduler_perf['carbon_efficiency'].idxmax()\n",
    "    best_carbon_score = scheduler_perf.loc[best_carbon, 'carbon_efficiency']\n",
    "    recommendations.append(f\"üå± For best carbon efficiency, use '{best_carbon}' scheduler (score: {best_carbon_score:.3f})\")\n",
    "    \n",
    "    # Lowest energy consumption\n",
    "    lowest_energy = scheduler_perf['energy_consumption'].idxmin()\n",
    "    lowest_energy_score = scheduler_perf.loc[lowest_energy, 'energy_consumption']\n",
    "    recommendations.append(f\"‚ö° For lowest energy consumption, use '{lowest_energy}' scheduler ({lowest_energy_score:.1f}W)\")\n",
    "    \n",
    "    # Best performance\n",
    "    best_perf = scheduler_perf['performance_score'].idxmax()\n",
    "    best_perf_score = scheduler_perf.loc[best_perf, 'performance_score']\n",
    "    recommendations.append(f\"üöÄ For best performance, use '{best_perf}' scheduler (score: {best_perf_score:.3f})\")\n",
    "    \n",
    "    # Workload-specific recommendations\n",
    "    workload_perf = df.groupby(['workload_type', 'scheduler'])['carbon_efficiency'].mean().unstack()\n",
    "    for workload in workload_perf.index:\n",
    "        best_scheduler = workload_perf.loc[workload].idxmax()\n",
    "        best_score = workload_perf.loc[workload, best_scheduler]\n",
    "        recommendations.append(f\"üìã For '{workload}' workloads, use '{best_scheduler}' scheduler (carbon efficiency: {best_score:.3f})\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "recommendations = generate_recommendations(df_main)\n",
    "\n",
    "print(\"üí° Performance Recommendations:\")\n",
    "print(\"=\" * 50)\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results\n",
    "\n",
    "Let's save our analysis results for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results summary\n",
    "results_summary = {\n",
    "    'analysis_date': datetime.now().isoformat(),\n",
    "    'dataset_info': {\n",
    "        'main_dataset_samples': len(df_main),\n",
    "        'schedulers_tested': df_main['scheduler'].unique().tolist(),\n",
    "        'node_types': df_main['node_type'].unique().tolist(),\n",
    "        'workload_types': df_main['workload_type'].unique().tolist()\n",
    "    },\n",
    "    'scheduler_performance': scheduler_stats.to_dict(),\n",
    "    'statistical_tests': {\n",
    "        'carbon_efficiency': carbon_tests.to_dict('records'),\n",
    "        'energy_consumption': energy_tests.to_dict('records')\n",
    "    },\n",
    "    'recommendations': recommendations\n",
    "}\n",
    "\n",
    "# Save results\n",
    "results_path = Path('../results')\n",
    "results_path.mkdir(exist_ok=True)\n",
    "\n",
    "with open(results_path / 'getting_started_analysis.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2, default=str)\n",
    "\n",
    "print(\"üíæ Results saved to: evaluation/results/getting_started_analysis.json\")\n",
    "print(\"\\n‚úÖ Analysis complete! Check the results directory for detailed outputs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you've completed the getting started tutorial, you can:\n",
    "\n",
    "1. **Explore Advanced Analysis**: Check out the other notebooks for more detailed analysis\n",
    "2. **Run Ablation Studies**: Use `02_Ablation_Studies.ipynb` to understand feature importance\n",
    "3. **Baseline Comparisons**: Use `03_Baseline_Comparison.ipynb` for detailed baseline analysis\n",
    "4. **Custom Experiments**: Create your own experiments using the framework\n",
    "5. **Integration**: Integrate the framework with your own Kubernetes cluster\n",
    "\n",
    "## Resources\n",
    "\n",
    "- **Documentation**: `evaluation/docs/`\n",
    "- **Configuration**: `evaluation/configs/`\n",
    "- **Example Data**: `evaluation/data/`\n",
    "- **Results**: `evaluation/results/`\n",
    "\n",
    "Happy evaluating! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}