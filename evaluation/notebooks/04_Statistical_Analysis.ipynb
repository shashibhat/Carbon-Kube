{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Statistical Analysis for Carbon-Efficient Scheduling\n",
    "\n",
    "This notebook provides comprehensive statistical analysis methods for evaluating carbon-efficient Kubernetes scheduling algorithms.\n",
    "\n",
    "## Statistical Methods Covered\n",
    "\n",
    "1. **Descriptive Statistics**: Central tendency, variability, and distribution analysis\n",
    "2. **Hypothesis Testing**: t-tests, ANOVA, non-parametric tests\n",
    "3. **Effect Size Analysis**: Cohen's d, eta-squared, confidence intervals\n",
    "4. **Bootstrap Methods**: Confidence intervals and significance testing\n",
    "5. **Regression Analysis**: Linear, polynomial, and robust regression\n",
    "6. **Time Series Analysis**: Trend analysis, seasonality, forecasting\n",
    "\n",
    "## Analysis Objectives\n",
    "\n",
    "- **Validate Performance Claims**: Statistically verify scheduler improvements\n",
    "- **Quantify Uncertainty**: Provide confidence intervals for estimates\n",
    "- **Compare Multiple Schedulers**: Handle multiple comparison problems\n",
    "- **Model Relationships**: Understand factors affecting performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Statistical libraries\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, kruskal, f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"Set2\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "data_path = Path('../data')\n",
    "datasets = {}\n",
    "\n",
    "# Load main dataset\n",
    "try:\n",
    "    main_data = pd.read_csv(data_path / 'synthetic' / 'main_dataset.csv')\n",
    "    datasets['main'] = main_data\n",
    "    print(f\"‚úÖ Loaded main dataset: {len(main_data)} samples\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Main dataset not found\")\n",
    "\n",
    "# Load baseline comparison data\n",
    "baseline_files = ['baseline_kubernetes_default.csv', 'baseline_carbon_aware_v1.csv']\n",
    "baseline_data = pd.DataFrame()\n",
    "\n",
    "for file in baseline_files:\n",
    "    try:\n",
    "        df = pd.read_csv(data_path / 'synthetic' / file)\n",
    "        scheduler_name = file.replace('baseline_', '').replace('.csv', '')\n",
    "        df['scheduler'] = scheduler_name\n",
    "        baseline_data = pd.concat([baseline_data, df], ignore_index=True)\n",
    "        print(f\"‚úÖ Loaded {scheduler_name}: {len(df)} samples\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Could not load {file}\")\n",
    "\n",
    "if not baseline_data.empty:\n",
    "    datasets['baseline'] = baseline_data\n",
    "    print(f\"üìä Combined baseline data: {len(baseline_data)} samples\")\n",
    "\n",
    "print(f\"\\nüìà Total datasets loaded: {len(datasets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comprehensive Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_hypothesis_testing(group1, group2, group1_name, group2_name, metric_name):\n",
    "    \"\"\"Perform comprehensive hypothesis testing between two groups\"\"\"\n",
    "    results = {\n",
    "        'metric': metric_name,\n",
    "        'group1': group1_name,\n",
    "        'group2': group2_name,\n",
    "        'group1_n': len(group1),\n",
    "        'group2_n': len(group2),\n",
    "        'group1_mean': group1.mean(),\n",
    "        'group2_mean': group2.mean()\n",
    "    }\n",
    "    \n",
    "    # Independent t-test\n",
    "    t_stat, t_p = ttest_ind(group1, group2)\n",
    "    results['t_test'] = {\n",
    "        'statistic': t_stat,\n",
    "        'p_value': t_p,\n",
    "        'significant': t_p < 0.05\n",
    "    }\n",
    "    \n",
    "    # Mann-Whitney U test (non-parametric)\n",
    "    u_stat, u_p = mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "    results['mann_whitney'] = {\n",
    "        'statistic': u_stat,\n",
    "        'p_value': u_p,\n",
    "        'significant': u_p < 0.05\n",
    "    }\n",
    "    \n",
    "    # Effect size (Cohen's d)\n",
    "    pooled_std = np.sqrt(((len(group1) - 1) * group1.var() + \n",
    "                         (len(group2) - 1) * group2.var()) / \n",
    "                        (len(group1) + len(group2) - 2))\n",
    "    cohens_d = (group2.mean() - group1.mean()) / pooled_std\n",
    "    results['effect_size'] = {\n",
    "        'cohens_d': cohens_d,\n",
    "        'magnitude': 'Small' if abs(cohens_d) < 0.5 else 'Medium' if abs(cohens_d) < 0.8 else 'Large'\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Perform hypothesis testing on baseline data\n",
    "if 'baseline' in datasets:\n",
    "    schedulers = datasets['baseline']['scheduler'].unique()\n",
    "    reference_scheduler = 'kubernetes_default'\n",
    "    \n",
    "    if reference_scheduler in schedulers:\n",
    "        ref_data = datasets['baseline'][datasets['baseline']['scheduler'] == reference_scheduler]\n",
    "        \n",
    "        hypothesis_results = []\n",
    "        \n",
    "        for scheduler in schedulers:\n",
    "            if scheduler != reference_scheduler:\n",
    "                comp_data = datasets['baseline'][datasets['baseline']['scheduler'] == scheduler]\n",
    "                \n",
    "                # Test carbon efficiency\n",
    "                if 'carbon_efficiency' in ref_data.columns:\n",
    "                    result = comprehensive_hypothesis_testing(\n",
    "                        ref_data['carbon_efficiency'].dropna(),\n",
    "                        comp_data['carbon_efficiency'].dropna(),\n",
    "                        reference_scheduler,\n",
    "                        scheduler,\n",
    "                        'carbon_efficiency'\n",
    "                    )\n",
    "                    hypothesis_results.append(result)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"üß™ Comprehensive Hypothesis Testing Results:\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for result in hypothesis_results:\n",
    "            print(f\"\\nüìä {result['group2']} vs {result['group1']} ({result['metric']})\")\n",
    "            print(f\"   Sample sizes: {result['group1_n']} vs {result['group2_n']}\")\n",
    "            print(f\"   Means: {result['group1_mean']:.4f} vs {result['group2_mean']:.4f}\")\n",
    "            print(f\"   T-test p-value: {result['t_test']['p_value']:.4f} {'‚úÖ' if result['t_test']['significant'] else '‚ùå'}\")\n",
    "            print(f\"   Mann-Whitney p-value: {result['mann_whitney']['p_value']:.4f} {'‚úÖ' if result['mann_whitney']['significant'] else '‚ùå'}\")\n",
    "            print(f\"   Effect size: {result['effect_size']['cohens_d']:.4f} ({result['effect_size']['magnitude']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bootstrap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_confidence_interval(data, statistic_func, n_bootstrap=1000, confidence_level=0.95):\n",
    "    \"\"\"Calculate bootstrap confidence interval for any statistic\"\"\"\n",
    "    bootstrap_stats = []\n",
    "    n = len(data)\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        bootstrap_sample = np.random.choice(data, size=n, replace=True)\n",
    "        bootstrap_stat = statistic_func(bootstrap_sample)\n",
    "        bootstrap_stats.append(bootstrap_stat)\n",
    "    \n",
    "    bootstrap_stats = np.array(bootstrap_stats)\n",
    "    \n",
    "    # Calculate confidence interval\n",
    "    alpha = 1 - confidence_level\n",
    "    lower_percentile = (alpha/2) * 100\n",
    "    upper_percentile = (1 - alpha/2) * 100\n",
    "    \n",
    "    ci_lower = np.percentile(bootstrap_stats, lower_percentile)\n",
    "    ci_upper = np.percentile(bootstrap_stats, upper_percentile)\n",
    "    \n",
    "    return {\n",
    "        'statistic': statistic_func(data),\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper,\n",
    "        'bootstrap_distribution': bootstrap_stats\n",
    "    }\n",
    "\n",
    "# Perform bootstrap analysis\n",
    "if 'baseline' in datasets:\n",
    "    schedulers = datasets['baseline']['scheduler'].unique()\n",
    "    reference_scheduler = 'kubernetes_default'\n",
    "    \n",
    "    if reference_scheduler in schedulers and 'carbon_efficiency' in datasets['baseline'].columns:\n",
    "        ref_data = datasets['baseline'][datasets['baseline']['scheduler'] == reference_scheduler]['carbon_efficiency'].dropna()\n",
    "        \n",
    "        print(\"üîÑ Bootstrap Analysis Results:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Bootstrap confidence interval for reference scheduler\n",
    "        ref_bootstrap = bootstrap_confidence_interval(ref_data, np.mean)\n",
    "        print(f\"\\nüìä {reference_scheduler} Carbon Efficiency:\")\n",
    "        print(f\"   Mean: {ref_bootstrap['statistic']:.4f}\")\n",
    "        print(f\"   95% CI: [{ref_bootstrap['ci_lower']:.4f}, {ref_bootstrap['ci_upper']:.4f}]\")\n",
    "        \n",
    "        # Compare with other schedulers\n",
    "        for scheduler in schedulers:\n",
    "            if scheduler != reference_scheduler:\n",
    "                comp_data = datasets['baseline'][datasets['baseline']['scheduler'] == scheduler]['carbon_efficiency'].dropna()\n",
    "                \n",
    "                if len(comp_data) > 0:\n",
    "                    comp_bootstrap = bootstrap_confidence_interval(comp_data, np.mean)\n",
    "                    \n",
    "                    print(f\"\\nüìä {scheduler}:\")\n",
    "                    print(f\"   Mean: {comp_bootstrap['statistic']:.4f}\")\n",
    "                    print(f\"   95% CI: [{comp_bootstrap['ci_lower']:.4f}, {comp_bootstrap['ci_upper']:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary and Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export statistical analysis results\n",
    "analysis_summary = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'analysis_type': 'comprehensive_statistical_analysis',\n",
    "    'datasets_analyzed': list(datasets.keys()),\n",
    "    'methods_used': [\n",
    "        'hypothesis_testing',\n",
    "        'bootstrap_methods',\n",
    "        'effect_size_analysis'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "results_dir = Path('../results')\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save results\n",
    "with open(results_dir / 'statistical_analysis_summary.json', 'w') as f:\n",
    "    json.dump(analysis_summary, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ Statistical analysis complete!\")\n",
    "print(\"üìä Results saved to: ../results/statistical_analysis_summary.json\")\n",
    "print(\"\\nüîç Key Insights:\")\n",
    "print(\"   ‚Ä¢ Use normality tests to choose appropriate statistical methods\")\n",
    "print(\"   ‚Ä¢ Bootstrap methods provide robust confidence intervals\")\n",
    "print(\"   ‚Ä¢ Effect size quantifies practical significance\")\n",
    "print(\"   ‚Ä¢ Multiple comparison corrections prevent false discoveries\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}