{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablation Studies - Understanding Feature Importance\n",
    "\n",
    "This notebook demonstrates how to perform ablation studies to understand which features and components contribute most to the performance of carbon-efficient Kubernetes scheduling algorithms.\n",
    "\n",
    "## What are Ablation Studies?\n",
    "\n",
    "Ablation studies systematically remove or disable components/features to understand their individual contributions to overall performance. This helps:\n",
    "\n",
    "- **Identify critical features**: Which features are most important?\n",
    "- **Understand interactions**: How do features interact with each other?\n",
    "- **Optimize complexity**: Can we achieve similar performance with fewer features?\n",
    "- **Debug performance**: Which components might be causing issues?\n",
    "\n",
    "## Study Design\n",
    "\n",
    "We'll analyze the impact of removing different scheduling features:\n",
    "1. **Carbon awareness**: Remove carbon efficiency considerations\n",
    "2. **Energy optimization**: Remove energy consumption optimization\n",
    "3. **Load balancing**: Remove load balancing features\n",
    "4. **Resource prediction**: Remove predictive resource allocation\n",
    "5. **Node affinity**: Remove node affinity rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import json\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Ablation Study Data\n",
    "\n",
    "Let's load the ablation study datasets that simulate different feature combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ablation study datasets\n",
    "data_path = Path('../data')\n",
    "ablation_datasets = {}\n",
    "\n",
    "# Define ablation scenarios\n",
    "ablation_scenarios = [\n",
    "    'full_features',\n",
    "    'no_carbon_awareness',\n",
    "    'no_energy_optimization',\n",
    "    'no_load_balancing',\n",
    "    'no_resource_prediction',\n",
    "    'no_node_affinity',\n",
    "    'minimal_features'\n",
    "]\n",
    "\n",
    "for scenario in ablation_scenarios:\n",
    "    try:\n",
    "        path = data_path / 'synthetic' / f'ablation_{scenario}.csv'\n",
    "        ablation_datasets[scenario] = pd.read_csv(path)\n",
    "        print(f\"‚úÖ Loaded {scenario}: {len(ablation_datasets[scenario])} samples\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Could not load {scenario}\")\n",
    "\n",
    "print(f\"\\nüìä Loaded {len(ablation_datasets)} ablation scenarios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all ablation data for analysis\n",
    "if ablation_datasets:\n",
    "    combined_ablation = pd.DataFrame()\n",
    "    \n",
    "    for scenario, df in ablation_datasets.items():\n",
    "        df_copy = df.copy()\n",
    "        df_copy['ablation_scenario'] = scenario\n",
    "        combined_ablation = pd.concat([combined_ablation, df_copy], ignore_index=True)\n",
    "    \n",
    "    print(f\"üìà Combined ablation dataset: {len(combined_ablation)} samples\")\n",
    "    print(f\"üî¨ Scenarios: {combined_ablation['ablation_scenario'].unique()}\")\n",
    "    \n",
    "    # Display sample data\n",
    "    print(\"\\nüìã Sample Data:\")\n",
    "    display(combined_ablation.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Performance Impact Analysis\n",
    "\n",
    "Let's analyze how removing each feature affects key performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics by ablation scenario\n",
    "if not combined_ablation.empty:\n",
    "    performance_metrics = combined_ablation.groupby('ablation_scenario')[[\n",
    "        'carbon_efficiency', 'energy_consumption', 'performance_score', \n",
    "        'response_time', 'throughput', 'resource_utilization'\n",
    "    ]].agg(['mean', 'std', 'count']).round(3)\n",
    "    \n",
    "    print(\"üìä Performance Metrics by Ablation Scenario:\")\n",
    "    display(performance_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance impact\n",
    "if not combined_ablation.empty:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    metrics = ['carbon_efficiency', 'energy_consumption', 'performance_score', \n",
    "               'response_time', 'throughput', 'resource_utilization']\n",
    "    titles = ['Carbon Efficiency', 'Energy Consumption (W)', 'Performance Score',\n",
    "              'Response Time (ms)', 'Throughput (req/s)', 'Resource Utilization (%)']\n",
    "    \n",
    "    for i, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "        row, col = i // 3, i % 3\n",
    "        \n",
    "        # Box plot by ablation scenario\n",
    "        combined_ablation.boxplot(column=metric, by='ablation_scenario', ax=axes[row, col])\n",
    "        axes[row, col].set_title(f'{title} by Ablation Scenario')\n",
    "        axes[row, col].set_xlabel('Ablation Scenario')\n",
    "        axes[row, col].set_ylabel(title)\n",
    "        axes[row, col].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.suptitle('')  # Remove automatic title\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Importance Ranking\n",
    "\n",
    "Let's calculate the relative importance of each feature by measuring performance degradation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_importance(df, baseline_scenario='full_features'):\n",
    "    \"\"\"Calculate feature importance based on performance degradation\"\"\"\n",
    "    if baseline_scenario not in df['ablation_scenario'].values:\n",
    "        print(f\"‚ùå Baseline scenario '{baseline_scenario}' not found\")\n",
    "        return None\n",
    "    \n",
    "    # Get baseline performance\n",
    "    baseline_data = df[df['ablation_scenario'] == baseline_scenario]\n",
    "    baseline_metrics = baseline_data[[\n",
    "        'carbon_efficiency', 'energy_consumption', 'performance_score'\n",
    "    ]].mean()\n",
    "    \n",
    "    # Calculate importance for each ablation scenario\n",
    "    importance_results = []\n",
    "    \n",
    "    for scenario in df['ablation_scenario'].unique():\n",
    "        if scenario == baseline_scenario:\n",
    "            continue\n",
    "            \n",
    "        scenario_data = df[df['ablation_scenario'] == scenario]\n",
    "        scenario_metrics = scenario_data[[\n",
    "            'carbon_efficiency', 'energy_consumption', 'performance_score'\n",
    "        ]].mean()\n",
    "        \n",
    "        # Calculate relative changes (negative for degradation)\n",
    "        carbon_change = (scenario_metrics['carbon_efficiency'] - baseline_metrics['carbon_efficiency']) / baseline_metrics['carbon_efficiency'] * 100\n",
    "        energy_change = (scenario_metrics['energy_consumption'] - baseline_metrics['energy_consumption']) / baseline_metrics['energy_consumption'] * 100\n",
    "        perf_change = (scenario_metrics['performance_score'] - baseline_metrics['performance_score']) / baseline_metrics['performance_score'] * 100\n",
    "        \n",
    "        # Calculate overall impact (weighted average)\n",
    "        overall_impact = (carbon_change * 0.4 + (-energy_change) * 0.3 + perf_change * 0.3)\n",
    "        \n",
    "        importance_results.append({\n",
    "            'Feature Removed': scenario.replace('no_', '').replace('_', ' ').title(),\n",
    "            'Scenario': scenario,\n",
    "            'Carbon Efficiency Change (%)': carbon_change,\n",
    "            'Energy Consumption Change (%)': energy_change,\n",
    "            'Performance Score Change (%)': perf_change,\n",
    "            'Overall Impact Score': overall_impact,\n",
    "            'Importance Rank': 0  # Will be filled later\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame and rank by overall impact\n",
    "    importance_df = pd.DataFrame(importance_results)\n",
    "    importance_df = importance_df.sort_values('Overall Impact Score', ascending=False)\n",
    "    importance_df['Importance Rank'] = range(1, len(importance_df) + 1)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "if not combined_ablation.empty:\n",
    "    feature_importance = calculate_feature_importance(combined_ablation)\n",
    "    \n",
    "    if feature_importance is not None:\n",
    "        print(\"üèÜ Feature Importance Ranking:\")\n",
    "        display(feature_importance.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "if feature_importance is not None:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Overall impact score\n",
    "    axes[0, 0].barh(feature_importance['Feature Removed'], feature_importance['Overall Impact Score'], color='skyblue')\n",
    "    axes[0, 0].set_title('Overall Feature Impact Score')\n",
    "    axes[0, 0].set_xlabel('Impact Score (Higher = More Important)')\n",
    "    \n",
    "    # Carbon efficiency impact\n",
    "    axes[0, 1].barh(feature_importance['Feature Removed'], feature_importance['Carbon Efficiency Change (%)'], color='green')\n",
    "    axes[0, 1].set_title('Carbon Efficiency Impact')\n",
    "    axes[0, 1].set_xlabel('Change (%)')\n",
    "    \n",
    "    # Energy consumption impact\n",
    "    axes[1, 0].barh(feature_importance['Feature Removed'], feature_importance['Energy Consumption Change (%)'], color='red')\n",
    "    axes[1, 0].set_title('Energy Consumption Impact')\n",
    "    axes[1, 0].set_xlabel('Change (%)')\n",
    "    \n",
    "    # Performance score impact\n",
    "    axes[1, 1].barh(feature_importance['Feature Removed'], feature_importance['Performance Score Change (%)'], color='orange')\n",
    "    axes[1, 1].set_title('Performance Score Impact')\n",
    "    axes[1, 1].set_xlabel('Change (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Statistical Significance Testing\n",
    "\n",
    "Let's test if the performance differences are statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ablation_significance(df, baseline_scenario='full_features', metric='carbon_efficiency'):\n",
    "    \"\"\"Test statistical significance of ablation studies\"\"\"\n",
    "    if baseline_scenario not in df['ablation_scenario'].values:\n",
    "        return None\n",
    "    \n",
    "    baseline_data = df[df['ablation_scenario'] == baseline_scenario][metric]\n",
    "    results = []\n",
    "    \n",
    "    for scenario in df['ablation_scenario'].unique():\n",
    "        if scenario == baseline_scenario:\n",
    "            continue\n",
    "            \n",
    "        scenario_data = df[df['ablation_scenario'] == scenario][metric]\n",
    "        \n",
    "        # T-test\n",
    "        t_stat, t_pval = stats.ttest_ind(baseline_data, scenario_data)\n",
    "        \n",
    "        # Mann-Whitney U test\n",
    "        u_stat, u_pval = stats.mannwhitneyu(baseline_data, scenario_data, alternative='two-sided')\n",
    "        \n",
    "        # Effect size (Cohen's d)\n",
    "        pooled_std = np.sqrt(((len(baseline_data) - 1) * baseline_data.var() + \n",
    "                             (len(scenario_data) - 1) * scenario_data.var()) / \n",
    "                            (len(baseline_data) + len(scenario_data) - 2))\n",
    "        cohens_d = (baseline_data.mean() - scenario_data.mean()) / pooled_std\n",
    "        \n",
    "        results.append({\n",
    "            'Scenario': scenario,\n",
    "            'Feature Removed': scenario.replace('no_', '').replace('_', ' ').title(),\n",
    "            'Baseline Mean': baseline_data.mean(),\n",
    "            'Scenario Mean': scenario_data.mean(),\n",
    "            'Mean Difference': baseline_data.mean() - scenario_data.mean(),\n",
    "            'T-test p-value': t_pval,\n",
    "            'Mann-Whitney p-value': u_pval,\n",
    "            'Effect Size (Cohen\\'s d)': cohens_d,\n",
    "            'Significant (p<0.05)': t_pval < 0.05,\n",
    "            'Effect Size Category': 'Small' if abs(cohens_d) < 0.5 else 'Medium' if abs(cohens_d) < 0.8 else 'Large'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "if not combined_ablation.empty:\n",
    "    # Test significance for carbon efficiency\n",
    "    carbon_significance = test_ablation_significance(combined_ablation, metric='carbon_efficiency')\n",
    "    \n",
    "    if carbon_significance is not None:\n",
    "        print(\"üß™ Statistical Significance Tests - Carbon Efficiency:\")\n",
    "        display(carbon_significance.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test significance for energy consumption\n",
    "if not combined_ablation.empty:\n",
    "    energy_significance = test_ablation_significance(combined_ablation, metric='energy_consumption')\n",
    "    \n",
    "    if energy_significance is not None:\n",
    "        print(\"üß™ Statistical Significance Tests - Energy Consumption:\")\n",
    "        display(energy_significance.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Machine Learning Feature Importance\n",
    "\n",
    "Let's use machine learning to understand feature importance from a different perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for ML analysis\n",
    "if not combined_ablation.empty:\n",
    "    # Create feature matrix\n",
    "    ml_data = combined_ablation.copy()\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    categorical_cols = ['scheduler', 'node_type', 'workload_type', 'ablation_scenario']\n",
    "    label_encoders = {}\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in ml_data.columns:\n",
    "            le = LabelEncoder()\n",
    "            ml_data[f'{col}_encoded'] = le.fit_transform(ml_data[col])\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # Select features for ML model\n",
    "    feature_cols = [\n",
    "        'cpu_utilization', 'memory_utilization', 'network_io', 'disk_io',\n",
    "        'load_factor', 'scheduler_encoded', 'node_type_encoded', \n",
    "        'workload_type_encoded', 'ablation_scenario_encoded'\n",
    "    ]\n",
    "    \n",
    "    # Filter available columns\n",
    "    available_features = [col for col in feature_cols if col in ml_data.columns]\n",
    "    \n",
    "    if available_features:\n",
    "        X = ml_data[available_features]\n",
    "        y = ml_data['carbon_efficiency']\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Train Random Forest model\n",
    "        rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"ü§ñ Random Forest Model Performance:\")\n",
    "        print(f\"   MSE: {mse:.4f}\")\n",
    "        print(f\"   R¬≤: {r2:.4f}\")\n",
    "        \n",
    "        # Feature importance\n",
    "        feature_importance_ml = pd.DataFrame({\n",
    "            'Feature': available_features,\n",
    "            'Importance': rf_model.feature_importances_\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        print(\"\\nüéØ ML-Based Feature Importance:\")\n",
    "        display(feature_importance_ml.round(4))\n",
    "        \n",
    "        # Plot feature importance\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(feature_importance_ml['Feature'], feature_importance_ml['Importance'], color='lightcoral')\n",
    "        plt.title('Random Forest Feature Importance')\n",
    "        plt.xlabel('Importance Score')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ùå No suitable features found for ML analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interaction Effects Analysis\n",
    "\n",
    "Let's analyze how different features interact with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze interaction effects between workload types and ablation scenarios\n",
    "if not combined_ablation.empty:\n",
    "    interaction_analysis = combined_ablation.groupby(['workload_type', 'ablation_scenario'])[[\n",
    "        'carbon_efficiency', 'energy_consumption', 'performance_score'\n",
    "    ]].mean().round(3)\n",
    "    \n",
    "    print(\"üîÑ Interaction Effects - Workload Type vs Ablation Scenario:\")\n",
    "    display(interaction_analysis)\n",
    "    \n",
    "    # Visualize interaction effects\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    metrics = ['carbon_efficiency', 'energy_consumption', 'performance_score']\n",
    "    titles = ['Carbon Efficiency', 'Energy Consumption', 'Performance Score']\n",
    "    \n",
    "    for i, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "        # Create pivot table for heatmap\n",
    "        pivot_data = combined_ablation.pivot_table(\n",
    "            values=metric, \n",
    "            index='workload_type', \n",
    "            columns='ablation_scenario', \n",
    "            aggfunc='mean'\n",
    "        )\n",
    "        \n",
    "        sns.heatmap(pivot_data, annot=True, fmt='.3f', cmap='RdYlBu_r', ax=axes[i])\n",
    "        axes[i].set_title(f'{title} - Workload vs Ablation')\n",
    "        axes[i].set_xlabel('Ablation Scenario')\n",
    "        axes[i].set_ylabel('Workload Type')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Recommendations and Insights\n",
    "\n",
    "Based on our ablation study analysis, let's generate actionable recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ablation_recommendations(importance_df, significance_df):\n",
    "    \"\"\"Generate recommendations based on ablation study results\"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    if importance_df is not None and not importance_df.empty:\n",
    "        # Most important feature\n",
    "        most_important = importance_df.iloc[0]\n",
    "        recommendations.append(\n",
    "            f\"üèÜ Most Critical Feature: '{most_important['Feature Removed']}' \"\n",
    "            f\"(Impact Score: {most_important['Overall Impact Score']:.2f})\"\n",
    "        )\n",
    "        \n",
    "        # Least important feature\n",
    "        least_important = importance_df.iloc[-1]\n",
    "        recommendations.append(\n",
    "            f\"üîß Least Critical Feature: '{least_important['Feature Removed']}' \"\n",
    "            f\"(Impact Score: {least_important['Overall Impact Score']:.2f}) - Consider for optimization\"\n",
    "        )\n",
    "        \n",
    "        # Features with high carbon impact\n",
    "        high_carbon_impact = importance_df[\n",
    "            importance_df['Carbon Efficiency Change (%)'] < -10\n",
    "        ]\n",
    "        if not high_carbon_impact.empty:\n",
    "            features = \"', '\".join(high_carbon_impact['Feature Removed'].tolist())\n",
    "            recommendations.append(\n",
    "                f\"üå± High Carbon Impact Features: '{features}' - Essential for carbon efficiency\"\n",
    "            )\n",
    "    \n",
    "    if significance_df is not None and not significance_df.empty:\n",
    "        # Statistically significant features\n",
    "        significant_features = significance_df[\n",
    "            significance_df['Significant (p<0.05)'] == True\n",
    "        ]\n",
    "        if not significant_features.empty:\n",
    "            features = \"', '\".join(significant_features['Feature Removed'].tolist())\n",
    "            recommendations.append(\n",
    "                f\"üìä Statistically Significant Features: '{features}' - Reliable performance impact\"\n",
    "            )\n",
    "        \n",
    "        # Large effect size features\n",
    "        large_effect = significance_df[\n",
    "            significance_df['Effect Size Category'] == 'Large'\n",
    "        ]\n",
    "        if not large_effect.empty:\n",
    "            features = \"', '\".join(large_effect['Feature Removed'].tolist())\n",
    "            recommendations.append(\n",
    "                f\"üí™ Large Effect Size Features: '{features}' - Major performance contributors\"\n",
    "            )\n",
    "    \n",
    "    # General recommendations\n",
    "    recommendations.extend([\n",
    "        \"üéØ Focus development efforts on the most critical features identified\",\n",
    "        \"‚öñÔ∏è Consider feature complexity vs. performance trade-offs for optimization\",\n",
    "        \"üîÑ Test feature interactions in different workload scenarios\",\n",
    "        \"üìà Monitor feature performance in production environments\",\n",
    "        \"üß™ Conduct regular ablation studies as the system evolves\"\n",
    "    ])\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Generate recommendations\n",
    "recommendations = generate_ablation_recommendations(\n",
    "    feature_importance if 'feature_importance' in locals() else None,\n",
    "    carbon_significance if 'carbon_significance' in locals() else None\n",
    ")\n",
    "\n",
    "print(\"üí° Ablation Study Recommendations:\")\n",
    "print(\"=\" * 60)\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Ablation Study Results\n",
    "\n",
    "Let's save our ablation study results for future reference and reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive results summary\n",
    "ablation_results = {\n",
    "    'study_info': {\n",
    "        'analysis_date': datetime.now().isoformat(),\n",
    "        'total_samples': len(combined_ablation) if not combined_ablation.empty else 0,\n",
    "        'scenarios_tested': combined_ablation['ablation_scenario'].unique().tolist() if not combined_ablation.empty else [],\n",
    "        'baseline_scenario': 'full_features'\n",
    "    },\n",
    "    'feature_importance': feature_importance.to_dict('records') if 'feature_importance' in locals() and feature_importance is not None else [],\n",
    "    'statistical_significance': {\n",
    "        'carbon_efficiency': carbon_significance.to_dict('records') if 'carbon_significance' in locals() and carbon_significance is not None else [],\n",
    "        'energy_consumption': energy_significance.to_dict('records') if 'energy_significance' in locals() and energy_significance is not None else []\n",
    "    },\n",
    "    'ml_feature_importance': feature_importance_ml.to_dict('records') if 'feature_importance_ml' in locals() else [],\n",
    "    'interaction_effects': interaction_analysis.to_dict() if 'interaction_analysis' in locals() else {},\n",
    "    'recommendations': recommendations,\n",
    "    'model_performance': {\n",
    "        'mse': mse if 'mse' in locals() else None,\n",
    "        'r2_score': r2 if 'r2' in locals() else None\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save results\n",
    "results_path = Path('../results')\n",
    "results_path.mkdir(exist_ok=True)\n",
    "\n",
    "with open(results_path / 'ablation_study_results.json', 'w') as f:\n",
    "    json.dump(ablation_results, f, indent=2, default=str)\n",
    "\n",
    "print(\"üíæ Ablation study results saved to: evaluation/results/ablation_study_results.json\")\n",
    "\n",
    "# Also save feature importance as CSV for easy access\n",
    "if 'feature_importance' in locals() and feature_importance is not None:\n",
    "    feature_importance.to_csv(results_path / 'feature_importance_ranking.csv', index=False)\n",
    "    print(\"üìä Feature importance ranking saved to: evaluation/results/feature_importance_ranking.csv\")\n",
    "\n",
    "print(\"\\n‚úÖ Ablation study analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This ablation study analysis has provided insights into:\n",
    "\n",
    "### Key Findings:\n",
    "1. **Feature Importance**: Identified which features contribute most to carbon efficiency\n",
    "2. **Statistical Significance**: Determined which features have reliable, measurable impact\n",
    "3. **Interaction Effects**: Understood how features perform differently across workload types\n",
    "4. **Optimization Opportunities**: Found features that could be simplified or removed\n",
    "\n",
    "### Next Steps:\n",
    "1. **Implementation**: Focus development on the most critical features\n",
    "2. **Optimization**: Consider removing or simplifying low-impact features\n",
    "3. **Testing**: Validate findings in production environments\n",
    "4. **Monitoring**: Track feature performance over time\n",
    "\n",
    "### Related Notebooks:\n",
    "- **01_Getting_Started.ipynb**: Basic framework usage\n",
    "- **03_Baseline_Comparison.ipynb**: Detailed baseline analysis\n",
    "- **04_Statistical_Analysis.ipynb**: Advanced statistical methods\n",
    "\n",
    "The results from this analysis should guide feature development priorities and system optimization efforts. üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}